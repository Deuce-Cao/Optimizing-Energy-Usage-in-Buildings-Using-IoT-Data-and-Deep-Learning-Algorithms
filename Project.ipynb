{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a8b9c3b6",
   "metadata": {},
   "source": [
    "# SEP 769 - Deep Learning Project - Optimizing Energy Usage in Buildings Using IoT Data and Deep Learning Algorithms\n",
    "> Hongqing Cao 400053625  \n",
    "Sushant Shailesh Panchal 400614293  \n",
    "Yanyi He 400651032  \n",
    "Yash Parab 400611922"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afbd89a1",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "This project aims to develop a machine learning-based system to optimize energy usage in buildings using data from IoT sensors. The goal is to reduce energy consumption and costs while maintaining occupant comfort and health. The project involves preprocessing data from IoT sensors, developing a deep learning model to optimize energy usage, and testing the model on new data to evaluate its effectiveness.\n",
    "\n",
    "The dataset [**Individual Household Electric Power Consumption dataset**](https://archive.ics.uci.edu/dataset/235) is retrived from UCI Machine Learning Repository, which contains measurements of electric power consumption in one household with a one-minute sampling rate over a period of almost 4 years. Different electrical quantities and some sub-metering values are available.\n",
    "\n",
    "### Objectives\n",
    "- Compare two different models over a subset of dataset, find the better performed model. \n",
    "- Tune, train, and evaluate the selected model, use this model to forecast future power consumption. \n",
    "- Visualize the predicted vs actual load, identify peak/vally power load time frames to suggest grid operation. \n",
    "\n",
    "\n",
    "### Dataset\n",
    "- **Source**: UCI Machine Learning Repository (https://archive.ics.uci.edu/dataset/235).\n",
    "- **Information**: This archive contains 2075259 measurements gathered in a house located in Sceaux (7km of Paris, France) between December 2006 and November 2010 (47 months). \n",
    "\n",
    "- **Features**: \n",
    "    - `date: dd/mm/yyyy`\n",
    "    - `time: hh:mm:ss`\n",
    "    - `global_active_power: float` Total household active power usage in kilowatts (kW)\n",
    "    - `reactive_power: float` Power not used for work, in KW\n",
    "    - `voltage: float` Voltage across the circuit, in V\n",
    "    - `global_intensity: float` Current drawn, in A\n",
    "    - `sub_metering_1: float` Energy drawn for kitchen, in Wh\n",
    "    - `sub_metering_2: float` Energy drawn for laundry, in Wh\n",
    "    - `sub_metering_3: float` Energy drawn for water heater and AC, in Wh\n",
    "\n",
    "- **Note**:  \n",
    "`global_active_power * 1000 / 60 - sub_metering_1 - sub_metering_2 - sub_metering_3`  \n",
    "represents the active energy consumed every minute (in watt hour) in the household by electrical equipment not measured in sub-meterings 1, 2 and 3.\n",
    "\n",
    "- **Missing Data**: The dataset contains some missing values in the measurements (nearly 1,25% of the rows). All calendar timestamps are present in the dataset but for some timestamps, the measurement values are missing (willed with `?`). \n",
    "\n",
    "### References\n",
    "- Marino et al. (2016), *Building Energy Load Forecasting using Deep Neural Networks*. \n",
    "- Bonetto & Rossi (2017), *Machine Learning Approaches to Energy Consumption Forecasting in Households*. \n",
    "- Gasparin et al. (2019), *Deep Learning for Time Series Forecasting: The Electric Load Case*. \n",
    "\n",
    "### Essential Notes\n",
    "- **Hardware**: The code in notebook in designed to best perform with CUDA GPUs, targeting RTX 4070. \n",
    "\n",
    "- **Environment**: Use `Python 3.11.7`, `NVIDIA-SMI 575.64.04`, `Driver Version: 577.00`, `CUDA Version: 12.9`. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "038c32f0",
   "metadata": {},
   "source": [
    "## 0. Environment Setup\n",
    "### Libaries Imported\n",
    "`numpy 2.1.3`  \n",
    "`matplotlib 3.10.3`  \n",
    "`pandas 2.3.1`  \n",
    "`tensorflow 2.19.0`  \n",
    "`scikit-learn 1.7.1`  \n",
    "`keras 3.10.0`  \n",
    "`tensorboard 2.19.0`  \n",
    "`seaborn 0.13.2`  \n",
    "\n",
    "### GPU Config\n",
    "set `set_memory_growth`, `mixed_precision`\n",
    "\n",
    "### Utility Functions\n",
    "``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "275f73ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-27 21:37:02.560467: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-07-27 21:37:02.575085: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1753666622.587391  131760 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1753666622.590941  131760 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1753666622.602750  131760 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1753666622.602768  131760 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1753666622.602769  131760 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1753666622.602769  131760 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-07-27 21:37:02.606860: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "### Libaries Imported\n",
    "from os import path\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from tensorflow import keras\n",
    "from keras.datasets import cifar10, mnist\n",
    "from keras import Sequential, layers\n",
    "from keras import backend as K\n",
    "from keras.optimizers import Adam, RMSprop, SGD\n",
    "from tensorboard.plugins.hparams import api as hp\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras import mixed_precision\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import gc\n",
    "\n",
    "%load_ext tensorboard\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e08fe581",
   "metadata": {},
   "outputs": [],
   "source": [
    "### GPU Config\n",
    "# use set_memory_growth to aallocate VRAM\n",
    "\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "\n",
    "if gpus:\n",
    "    for gpu in gpus:\n",
    "        tf.config.experimental.set_memory_growth(gpu, True)\n",
    "\n",
    "# use mixed_precision to accelrate GPU speed\n",
    "\n",
    "mixed_precision.set_global_policy('mixed_float16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8dc7d859",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Global Variables\n",
    "DATA_DIR = \"data\"\n",
    "RAW_DIR = DATA_DIR+\"/raw\"\n",
    "TRAIN_DIR = DATA_DIR+\"/train\"\n",
    "TEST_DIR = DATA_DIR+\"/test\"\n",
    "\n",
    "MODEL_DIR = \"model\"\n",
    "\n",
    "LOG_DIR = \"log\"\n",
    "HPARAM_DIR = LOG_DIR+\"/hparam\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8caa19e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Utility functions\n",
    "\n",
    "def delete_model(modelname, historyname):\n",
    "    '''function for delete model, history and free vram'''\n",
    "    global_vars = globals()\n",
    "    if modelname in globals():\n",
    "        del global_vars[modelname]\n",
    "    if historyname in globals():\n",
    "        del global_vars[historyname]\n",
    "    gc.collect()\n",
    "    K.clear_session()\n",
    "\n",
    "def inspect_data(df, name):\n",
    "    '''print summary data of a given dataframe, with\n",
    "    count\n",
    "    mean\n",
    "    std\n",
    "    min\n",
    "    25%\n",
    "    50%\n",
    "    75%\n",
    "    max\n",
    "    dtype\n",
    "    '''\n",
    "    print(f\"\\n{name} summary:\")\n",
    "    print(df.describe())\n",
    "    print(df.isnull().sum())\n",
    "\n",
    "def plot_time_series(df, column, start=None, end=None, title=None):\n",
    "    '''plot the raw time series data from time to end with corresponding column\n",
    "\n",
    "    column =  global_active_power, sub_metering_other, sub_metering_1/2/3'''\n",
    "    df_subset = df[start:end] if start or end else df\n",
    "    df_subset[column].plot(figsize=(12, 4), title=title or column)\n",
    "\n",
    "# def plot_hourly_avg(df, column):\n",
    "#     hourly_avg = df.groupby(df.index.hour)[column].mean()\n",
    "#     hourly_avg.plot(kind=\"bar\", figsize=(10, 4), title=f\"Average {column} by Hour\")\n",
    "\n",
    "# def plot_dayofweek_avg(df, column):\n",
    "#     dow_avg = df.groupby(df.index.dayofweek)[column].mean()\n",
    "#     dow_avg.plot(kind=\"bar\", figsize=(8, 4), title=f\"Average {column} by Day of Week\")\n",
    "\n",
    "# def plot_distribution(df, column):\n",
    "#     df[column].hist(bins=50, figsize=(6, 4), title=f\"Distribution of {column}\")\n",
    "\n",
    "# def plot_correlation_heatmap(df):\n",
    "#     plt.figure(figsize=(10, 6))\n",
    "#     sns.heatmap(df.corr(), annot=True, cmap=\"coolwarm\")\n",
    "#     plt.title(\"Feature Correlation Heatmap\")\n",
    "\n",
    "def plot_lagged_sample(X, y, feature_idx=0, sample_idx=0):\n",
    "    '''Visualize what an LSTM/S2S input-output pair looks like'''\n",
    "    plt.plot(X[sample_idx, :, feature_idx], label=\"Input sequence\")\n",
    "    plt.axhline(y[sample_idx], color='r', linestyle='--', label=\"Target\")\n",
    "    plt.legend()\n",
    "    plt.title(\"Lagged input and target\")\n",
    "    plt.show()\n",
    "\n",
    "def plot_forecast(y_true, y_pred, title=\"Forecast vs Actual\"):\n",
    "    '''plot forecast vs actual lines'''\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    plt.plot(y_true, label=\"Actual\")\n",
    "    plt.plot(y_pred, label=\"Forecast\")\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef731360",
   "metadata": {},
   "source": [
    "## 1. Data Preprocessing\n",
    "\n",
    "### Load Data\n",
    " - Load raw dataset\n",
    " - Convert data type\n",
    "\n",
    "### Resample Data\n",
    "Resample data to 1-hr\n",
    "\n",
    "### Handle Missing Data\n",
    "Reconstruct misssing data with linear interpolation\n",
    "\n",
    "### Save Raw Data\n",
    "Save to `data/raw`\n",
    "\n",
    "### Feature Engineering\n",
    " - `season_spring: binary` one-hot coded season transformed from `date`\n",
    " - `season_summer: binary` one-hot coded season transformed from `date`\n",
    " - `season_autumn: binary` one-hot coded season transformed from `date`\n",
    " - `season_winter: binary` one-hot coded season transformed from `date`\n",
    " - `day_of_week: int` categorical in `range(7)`, 0 Sunday, 1 Monday, 6 Saturday\n",
    " - `hour_sin, hour_cos: float` hour in transfromed from `time` in cyclical encoding, range [-1, 1]\n",
    " - `global_active_power: float` target variable, \n",
    " - `sub_metering_other: float` calculated by `global_active_power * 1000 / 60 - sub_metering_1 - sub_metering_2 - sub_metering_3`, \n",
    " - `reactive_power: float` drop\n",
    " - `voltage: float` drop\n",
    " - `global_intensity: float` drop\n",
    " - `sub_metering_1: float` existing raw feature\n",
    " - `sub_metering_2: float` existing raw feature\n",
    " - `sub_metering_3: float` existing raw feature\n",
    "\n",
    "### Save Feature Engineered Data\n",
    "Save to `data/raw`\n",
    "\n",
    "### Create Subsets (distinct)\n",
    " - `model_selection`: 1 month (~720 samples)\n",
    " - `hparam_tuning`: 1 month (~720 samples)\n",
    " - `train`: 12 months (~8600 samples)\n",
    " - `test`: 3 months (~2100 samples)\n",
    " - `test_1`: 3 months (~2100 samples) forecast\n",
    " - `test_2`: 3 months (~2100 samples) forecast\n",
    "\n",
    "### Save Subset Data\n",
    " - Store model selection, tuning, training data in `data/train` \n",
    " - Store  testing data in `data/test` \n",
    "\n",
    "### Normalization and Standarization\n",
    "Use `StandardScaler` for `global_active_power`, `sub_metering_other`, `sub_metering_1`, `sub_metering_2`, `sub_metering_3` \n",
    "\n",
    "### Save Normalized Data\n",
    "Store model selection, tuning, training data in `data/train` \n",
    "\n",
    "### Lagging Data\n",
    "Lag data by 1 weel = 168 hrs = 168 samples. \n",
    "Specify target variable \n",
    "\n",
    "### Save Final Processed Data\n",
    " - Store raw data in `/data/raw` \n",
    " - Store model selection, tuning, training data in `data/train` \n",
    " - Store  testing data in `data/test` \n",
    " - Store models in `model` \n",
    " - Store hyperparameter tuning log in `log/hparam`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4f88392b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Load Data\n",
    "# Load raw data\n",
    "chunks = []\n",
    "reader = pd.read_csv(\n",
    "    RAW_DIR+\"/household_power_consumption.txt\", \n",
    "    sep=\";\", \n",
    "    na_values='?',\n",
    "    low_memory=False,\n",
    "    chunksize=500_000\n",
    "    )\n",
    "\n",
    "for chunk in reader:\n",
    "    chunks.append(chunk)\n",
    "\n",
    "df = pd.concat(chunks)\n",
    "\n",
    "df.columns = df.columns.str.lower()\n",
    "df['datetime_str'] = df['date'] + ' ' + df['time']\n",
    "\n",
    "df['datetime'] = (pd.to_datetime(df['datetime_str'], dayfirst=True))\n",
    "df = df.drop(columns=['date', 'time', 'datetime_str'])\n",
    "df.set_index(\"datetime\", inplace=True)\n",
    "df.sort_index(inplace=True)\n",
    "\n",
    "# Convert from string/object to float\n",
    "df = df.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "15ff7033",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Resample Data\n",
    "# Resample to hourly mean\n",
    "df_hourly = df.resample('h').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d737b4e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Handle Missing Data\n",
    "df_hourly_reco = df_hourly.interpolate(method='linear', limit_direction='both')\n",
    "df_hourly_reco.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9eaf5b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save raw data\n",
    "df_hourly_reco.to_pickle(RAW_DIR+\"/hourly_reco.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "53675913",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load raw data\n",
    "df_hourly_reco = pd.read_pickle(RAW_DIR+\"/hourly_reco.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c35e3e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Feature Engineering\n",
    "df_hourly_reco['month'] = df_hourly_reco.index.month\n",
    "df_hourly_reco['season'] = df_hourly_reco.index.month % 12 // 3 \n",
    "# 1=spring, 2=summer, 3=fall, 0=winter\n",
    "\n",
    "season_map = {0: 'winter', 1: 'spring', 2: 'summer', 3: 'autumn'}\n",
    "df_hourly_reco['season_label'] = df_hourly_reco['season'].map(season_map)\n",
    "\n",
    "df_hourly_reco = pd.get_dummies(df_hourly_reco, columns=['season_label'], prefix='season')\n",
    "\n",
    "dow_mon0 = df_hourly_reco.index.dayofweek # 0=Monday\n",
    "dow_sun0 = (dow_mon0 + 1) % 7 # 0=Sunday\n",
    "df_hourly_reco['day_of_week'] = dow_sun0 # 0=Sunday\n",
    "\n",
    "\n",
    "df_hourly_reco['hour'] = df_hourly_reco.index.hour\n",
    "# For smoother time-of-day signals:\n",
    "df_hourly_reco['hour_sin'] = np.sin(2 * np.pi * df_hourly_reco['hour'] / 24)\n",
    "df_hourly_reco['hour_cos'] = np.cos(2 * np.pi * df_hourly_reco['hour'] / 24)\n",
    "\n",
    "df_hourly_reco['sub_metering_other'] = (\n",
    "    df_hourly_reco['global_active_power'] * 1000 / 60\n",
    "    - df_hourly_reco['sub_metering_1']\n",
    "    - df_hourly_reco['sub_metering_2']\n",
    "    - df_hourly_reco['sub_metering_3']\n",
    ")\n",
    "\n",
    "df_fe = df_hourly_reco.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "73ed7273",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Feature Engineering Continued\n",
    "drop_cols = ['month', 'season', 'hour', 'voltage', 'global_reactive_power', 'global_intensity']\n",
    "df_fe.drop(columns=drop_cols, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0c443e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Save Feature Engineered Data\n",
    "df_fe.to_pickle(RAW_DIR+\"/feature_engineered.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "14174927",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Load Feature Engineered Data\n",
    "df_fe=pd.read_pickle(RAW_DIR+\"/feature_engineered.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "92c10d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create Subsets (distinct)\n",
    "total_len = len(df_fe)\n",
    "\n",
    "# Subset sizes (in number of rows)\n",
    "model_sel_len = 720     # 1 month\n",
    "tune_len      = 720     # 1 month\n",
    "train_len     = 8760    # 12 months\n",
    "test_len      = 2160    # 3 months\n",
    "\n",
    "# Sequential slicing\n",
    "model_sel_df = df_fe.iloc[:model_sel_len]\n",
    "\n",
    "tune_df = df_fe.iloc[model_sel_len : model_sel_len + tune_len]\n",
    "\n",
    "train_df = df_fe.iloc[model_sel_len + tune_len : model_sel_len + tune_len + train_len]\n",
    "\n",
    "test_df = df_fe.iloc[model_sel_len + tune_len + train_len : model_sel_len + tune_len + train_len + test_len]\n",
    "\n",
    "test1_start = '2009-01-15'\n",
    "test1_end = '2009-04-15'\n",
    "\n",
    "test2_start = '2009-07-15'\n",
    "test2_end = '2009-10-15'\n",
    "\n",
    "test1_df = df_fe.loc[test1_start:test1_end]\n",
    "test2_df = df_fe.loc[test2_start:test2_end]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "277f7393",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Save Subsets\n",
    "model_sel_df.to_pickle(TRAIN_DIR+\"/model_selection.pkl\")\n",
    "tune_df.to_pickle(TRAIN_DIR+\"/hparam_tuning.pkl\")\n",
    "train_df.to_pickle(TRAIN_DIR+\"/train.pkl\")\n",
    "test_df.to_pickle(TEST_DIR+\"/test.pkl\")\n",
    "test1_df.to_pickle(TEST_DIR+\"/test1.pkl\")\n",
    "test2_df.to_pickle(TEST_DIR+\"/test2.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1a8eef2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Load Subsets\n",
    "model_sel_df = pd.read_pickle(TRAIN_DIR+\"/model_selection.pkl\")\n",
    "tune_df = pd.read_pickle(TRAIN_DIR+\"/hparam_tuning.pkl\")\n",
    "train_df = pd.read_pickle(TRAIN_DIR+\"/train.pkl\")\n",
    "test_df = pd.read_pickle(TEST_DIR+\"/test.pkl\")\n",
    "test1_df = pd.read_pickle(TEST_DIR+\"/test1.pkl\")\n",
    "test2_df = pd.read_pickle(TEST_DIR+\"/test2.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7554dda2",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Normalization and Standarization\n",
    "cols_to_scale = ['global_active_power', 'sub_metering_other', 'sub_metering_1', 'sub_metering_2', 'sub_metering_3']\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(train_df[cols_to_scale])\n",
    "\n",
    "def std_scale(df, scaler, cols_to_scale):\n",
    "    df_scaled = df.copy()\n",
    "    df_scaled[cols_to_scale] = scaler.transform(df[cols_to_scale])\n",
    "    return df_scaled\n",
    "\n",
    "\n",
    "model_sel_scaled = std_scale(model_sel_df, scaler, cols_to_scale)\n",
    "tune_scaled = std_scale(tune_df, scaler, cols_to_scale)\n",
    "train_scaled = std_scale(train_df, scaler, cols_to_scale)\n",
    "test_scaled = std_scale(test_df, scaler, cols_to_scale)\n",
    "test1_scaled = std_scale(test1_df, scaler, cols_to_scale)\n",
    "test2_scaled = std_scale(test2_df, scaler, cols_to_scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ee92e63f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Save Normalized Data\n",
    "model_sel_scaled.to_pickle(TRAIN_DIR+\"/model_selection_scaled.pkl\")\n",
    "tune_scaled.to_pickle(TRAIN_DIR+\"/hparam_tuning_scaled.pkl\")\n",
    "train_scaled.to_pickle(TRAIN_DIR+\"/train_scaled.pkl\")\n",
    "test_scaled.to_pickle(TEST_DIR+\"/test_scaled.pkl\")\n",
    "test1_scaled.to_pickle(TEST_DIR+\"/test1_scaled.pkl\")\n",
    "test2_scaled.to_pickle(TEST_DIR+\"/test2_scaled.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "43191de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Load Normalized Data\n",
    "model_sel_scaled = pd.read_pickle(TRAIN_DIR+\"/model_selection_scaled.pkl\")\n",
    "tune_scaled = pd.read_pickle(TRAIN_DIR+\"/hparam_tuning_scaled.pkl\")\n",
    "train_scaled = pd.read_pickle(TRAIN_DIR+\"/train_scaled.pkl\")\n",
    "test_scaled = pd.read_pickle(TEST_DIR+\"/test_scaled.pkl\")\n",
    "test1_scaled = pd.read_pickle(TEST_DIR+\"/test1_scaled.pkl\")\n",
    "test2_scaled = pd.read_pickle(TEST_DIR+\"/test2_scaled.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d28da335",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Lagging Data\n",
    "\n",
    "def create_lagged_sequences(df, target_col, lag_size=168, forecast_horizon=1):\n",
    "    features = df.drop(columns=[target_col]).values\n",
    "    target = df[target_col].values\n",
    "\n",
    "    num_samples = len(df) - lag_size - forecast_horizon + 1\n",
    "    num_features = features.shape[1]\n",
    "\n",
    "    X = np.zeros((num_samples, lag_size, num_features), dtype=np.float32)\n",
    "    y = np.zeros((num_samples, forecast_horizon), dtype=np.float32)\n",
    "\n",
    "    for i in range(num_samples):\n",
    "        X[i] = features[i : i + lag_size]\n",
    "        y[i] = target[i + lag_size : i + lag_size + forecast_horizon]\n",
    "\n",
    "    return X, y\n",
    "\n",
    "target_col='global_active_power'\n",
    "\n",
    "\n",
    "X_model_sel, y_model_sel = create_lagged_sequences(model_sel_scaled, target_col)\n",
    "X_tune, y_tune = create_lagged_sequences(tune_scaled, target_col)\n",
    "X_train, y_train = create_lagged_sequences(train_scaled, target_col)\n",
    "X_test, y_test = create_lagged_sequences(test_scaled, target_col)\n",
    "X_test1, y_test1 = create_lagged_sequences(test1_scaled, target_col)\n",
    "X_test2, y_test2= create_lagged_sequences(test2_scaled, target_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d88200c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Save Processed Data\n",
    "np.save(TRAIN_DIR+\"/X_model_sel.npy\", X_model_sel)\n",
    "np.save(TRAIN_DIR+\"/y_model_sel.npy\", y_model_sel)\n",
    "np.save(TRAIN_DIR+\"/X_tune.npy\", X_tune)\n",
    "np.save(TRAIN_DIR+\"/y_tune.npy\", y_tune)\n",
    "np.save(TRAIN_DIR+\"/X_train.npy\", X_train)\n",
    "np.save(TRAIN_DIR+\"/y_train.npy\", y_train)\n",
    "np.save(TRAIN_DIR+\"/X_test.npy\", X_test)\n",
    "np.save(TRAIN_DIR+\"/y_test.npy\", y_test)\n",
    "np.save(TRAIN_DIR+\"/X_test1.npy\", X_test1)\n",
    "np.save(TRAIN_DIR+\"/y_test1.npy\", y_test1)\n",
    "np.save(TRAIN_DIR+\"/X_test2.npy\", X_test2)\n",
    "np.save(TRAIN_DIR+\"/y_test2.npy\", y_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b95a826c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Load Processed Data\n",
    "y_model_sel = np.load(TRAIN_DIR+\"/y_model_sel.npy\")\n",
    "X_model_sel = np.load(TRAIN_DIR+\"/X_model_sel.npy\")\n",
    "X_tune = np.load(TRAIN_DIR+\"/X_tune.npy\")\n",
    "y_tune = np.load(TRAIN_DIR+\"/y_tune.npy\")\n",
    "X_train = np.load(TRAIN_DIR+\"/X_train.npy\")\n",
    "y_train = np.load(TRAIN_DIR+\"/y_train.npy\")\n",
    "X_test = np.load(TRAIN_DIR+\"/X_test.npy\")\n",
    "y_test = np.load(TRAIN_DIR+\"/y_test.npy\")\n",
    "X_test1 = np.load(TRAIN_DIR+\"/X_test1.npy\")\n",
    "y_test1 = np.load(TRAIN_DIR+\"/y_test1.npy\")\n",
    "X_test2 = np.load(TRAIN_DIR+\"/X_test2.npy\")\n",
    "y_test2 = np.load(TRAIN_DIR+\"/y_test2.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88fab193",
   "metadata": {},
   "source": [
    "## 2. Model Selection\n",
    "Train both model with `model_selection` subset with `validation_split = 0.2`. \n",
    "\n",
    "### LSTM\n",
    "\n",
    "### S2S\n",
    "Seq2seq \n",
    "\n",
    "### Evaluation\n",
    "Use $\\mathrm{RMSE}$ to compare models\n",
    "\n",
    "### Save Model\n",
    "Save both models in `model`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d372a399",
   "metadata": {},
   "outputs": [],
   "source": [
    "### LSTM\n",
    "def build_LSTM(input_shape, units=64, dropout_rate=0.2, learning_rate = 0.01):\n",
    "    model = Sequential([\n",
    "        layers.Input(shape=input_shape),\n",
    "        layers.LSTM(units),\n",
    "        layers.Dropout(dropout_rate),\n",
    "        layers.Dense(1)\n",
    "    ])\n",
    "    model.compile(optimizer=Adam(learning_rate=learning_rate), loss='mse', metrics=['mae'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5c74e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### S2S\n",
    "# class Encoder(layers.Layer):\n",
    "#     def __init__(self, input_shape, units):\n",
    "#         self.input_shape = input_shape\n",
    "#         self.units = units\n",
    "\n",
    "#         # The input layer converts tokens to vectors\n",
    "#         self.input = layers.Input(shape = input_shape)\n",
    "\n",
    "#         # The LSTM layer processes those vectors sequentially.\n",
    "#         self.lstm = layers.LSTM(\n",
    "#             units,\n",
    "#             return_state = True, \n",
    "#         )\n",
    "\n",
    "#     def call(self, X):\n",
    "#         X = self.input(X)\n",
    "#         state = self.lstm\n",
    "#         return state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fa2accd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# class Decoder(layers.Layer):\n",
    "#     def __init__(self, output_shape, units):\n",
    "#         super(Decoder, self).__init__()\n",
    "#         self.output_shape = output_shape\n",
    "#         self.units = units\n",
    "\n",
    "#         # 1. The input layer converts token IDs to vectors\n",
    "#         self.input = layers.Input(shape=output_shape)\n",
    "\n",
    "#         # 2. The LSTM keeps track of what's been generated so far.\n",
    "#         self.lstm = layers.LSTM(\n",
    "#             units,\n",
    "#             return_sequences=True,\n",
    "#             return_state=True,\n",
    "#         )\n",
    "#         # 3. This fully connected layer produces the logits for each\n",
    "#         # output token.\n",
    "#         self.dense  = layers.Dense(output_shape)\n",
    "\n",
    "#     def call(self, X,\n",
    "#          state=None,\n",
    "#          return_state=False):  \n",
    "#         # 1. Lookup the embeddings\n",
    "#         X = self.input(X)\n",
    "#         # 2. Process the target sequence.\n",
    "#         X, state = self.lstm(X, initial_state=state)\n",
    "#         # 3. Generate logit predictions for the next token.\n",
    "#         logits = self.dense(X)\n",
    "\n",
    "#         if return_state:\n",
    "#             return logits, state\n",
    "#         else:\n",
    "#             return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd67b807",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">19,456</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │        \u001b[38;5;34m19,456\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m65\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">19,521</span> (76.25 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m19,521\u001b[0m (76.25 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">19,521</span> (76.25 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m19,521\u001b[0m (76.25 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "AttributeError",
     "evalue": "property 'input' of 'Encoder' object has no setter",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[52]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      7\u001b[39m model_sel_LSTM = build_LSTM(input_shape)\n\u001b[32m      8\u001b[39m model_sel_LSTM.summary()\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m encoder = \u001b[43mEncoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_shape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43munits\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m64\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     11\u001b[39m decoder = Decoder(output_shape, units=\u001b[32m64\u001b[39m)\n\u001b[32m     13\u001b[39m init_state = encoder(X_model_sel)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[50]\u001b[39m\u001b[32m, line 8\u001b[39m, in \u001b[36mEncoder.__init__\u001b[39m\u001b[34m(self, input_shape, units)\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;28mself\u001b[39m.units = units\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# The input layer converts tokens to vectors\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43minput\u001b[49m = layers.Input(shape = input_shape)\n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m# The LSTM layer processes those vectors sequentially.\u001b[39;00m\n\u001b[32m     11\u001b[39m \u001b[38;5;28mself\u001b[39m.lstm = layers.LSTM(\n\u001b[32m     12\u001b[39m     units,\n\u001b[32m     13\u001b[39m     return_state = \u001b[38;5;28;01mTrue\u001b[39;00m, \n\u001b[32m     14\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/DeepL/deeplenv/lib/python3.11/site-packages/keras/src/layers/layer.py:1535\u001b[39m, in \u001b[36mLayer.__setattr__\u001b[39m\u001b[34m(self, name, value)\u001b[39m\n\u001b[32m   1533\u001b[39m         \u001b[38;5;28mself\u001b[39m._initialize_tracker()\n\u001b[32m   1534\u001b[39m     value = \u001b[38;5;28mself\u001b[39m._tracker.track(value)\n\u001b[32m-> \u001b[39m\u001b[32m1535\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__setattr__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/DeepL/deeplenv/lib/python3.11/site-packages/keras/src/backend/tensorflow/trackable.py:28\u001b[39m, in \u001b[36mKerasAutoTrackable.__setattr__\u001b[39m\u001b[34m(self, name, value)\u001b[39m\n\u001b[32m     24\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m_self_setattr_tracking\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[32m     25\u001b[39m     value = sticky_attribute_assignment(\n\u001b[32m     26\u001b[39m         trackable=\u001b[38;5;28mself\u001b[39m, value=value, name=name\n\u001b[32m     27\u001b[39m     )\n\u001b[32m---> \u001b[39m\u001b[32m28\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__setattr__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/DeepL/deeplenv/lib/python3.11/site-packages/tensorflow/python/trackable/autotrackable.py:70\u001b[39m, in \u001b[36mAutoTrackable.__setattr__\u001b[39m\u001b[34m(self, name, value)\u001b[39m\n\u001b[32m     67\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m_self_setattr_tracking\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[32m     68\u001b[39m   value = data_structures.sticky_attribute_assignment(\n\u001b[32m     69\u001b[39m       trackable=\u001b[38;5;28mself\u001b[39m, value=value, name=name)\n\u001b[32m---> \u001b[39m\u001b[32m70\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mAutoTrackable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__setattr__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mAttributeError\u001b[39m: property 'input' of 'Encoder' object has no setter"
     ]
    }
   ],
   "source": [
    "delete_model('model_sel_LSTM', 'history_sel_LSTM')\n",
    "delete_model('model_sel_S2S', 'history_sel_S2S')\n",
    "\n",
    "input_shape = X_model_sel.shape[1:]\n",
    "output_shape = y_model_sel.shape[1:]\n",
    "\n",
    "model_sel_LSTM = build_LSTM(input_shape)\n",
    "model_sel_LSTM.summary()\n",
    "\n",
    "# encoder = Encoder(input_shape, units=64)\n",
    "# decoder = Decoder(output_shape, units=64)\n",
    "\n",
    "# init_state = encoder(X_model_sel)\n",
    "# output, state = decoder(X_model_sel, init_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ed2db3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7f6c164c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65f62c46",
   "metadata": {},
   "source": [
    "## 3. Model Train\n",
    "### Hyperparameter Tuning\n",
    "Tune hyperparameters on `hparam_tuning` subset with `validation_split = 0.2`. \n",
    "\n",
    "Hyperparameters to be tuned:\n",
    " - `learning_rate`\n",
    " - `num_layers`\n",
    " - `hidden_size`\n",
    " - `dropout`\n",
    " - `etc`\n",
    "\n",
    "Save logs in `log/hparam`\n",
    "\n",
    "### Train Tuned Model\n",
    "Train model on `train` subset with `validation_split = 0.2`. \n",
    "\n",
    "### Save Model\n",
    "Save model in `model`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c69f9a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Hyperparameter Tuning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1796d8ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Train Tuned Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a17dea9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Save Model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8c463a3",
   "metadata": {},
   "source": [
    "## 4. Model Evaluation\n",
    "\n",
    "### Evaluate Model\n",
    "Use `test` subset to evaluate model with metrics $\\mathrm{RMSE}$ and $\\mathrm{MAE}$. \n",
    "\n",
    "### Visualization\n",
    "Plots to be visualized\n",
    " - Actual vs Predicted \n",
    " - Loss over Epochs\n",
    "\n",
    "### Analyze Model Performance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1b044cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "391c2926",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "569b9a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Analyze Model Performance\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15c1159a",
   "metadata": {},
   "source": [
    "## 5. Forecaste to Energy Optimization\n",
    "\n",
    "### Use `test1` and `test2` subset, take one day/week ahead, predict the `global_active_power` of the subset. \n",
    "\n",
    "### Merics\n",
    "RMSE, MAE\n",
    "\n",
    "### Visualize Result\n",
    "Predicted vs Actual\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeplenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
